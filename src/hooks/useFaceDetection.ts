
import { useState, useEffect, useRef } from 'react';

export type DetectedEmotion = 'feliz' | 'triste' | 'raiva' | 'surpreso' | 'neutro' | 'cansado';

interface FaceDetectionResult {
  emotion: DetectedEmotion;
  confidence: number;
}

interface EmotionHistory {
  emotion: DetectedEmotion;
  confidence: number;
  timestamp: number;
}

interface UseFaceDetectionReturn {
  isModelLoaded: boolean;
  currentEmotion: DetectedEmotion | null;
  confidence: number;
  isDetecting: boolean;
  error: string | null;
  loadModels: () => Promise<void>;
  startDetection: (videoElement: HTMLVideoElement) => void;
  stopDetection: () => void;
}

export const useFaceDetection = (onEmotionChange?: (emotion: DetectedEmotion) => void): UseFaceDetectionReturn => {
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [currentEmotion, setCurrentEmotion] = useState<DetectedEmotion | null>(null);
  const [confidence, setConfidence] = useState(0);
  const [isDetecting, setIsDetecting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const previousFrameRef = useRef<ImageData | null>(null);
  
  // Hist√≥rico para suaviza√ß√£o
  const emotionHistoryRef = useRef<EmotionHistory[]>([]);
  const lastEmotionChangeRef = useRef<number>(0);
  
  // Configura√ß√µes de estabilidade
  const HISTORY_SIZE = 5; // √öltimas 5 detec√ß√µes
  const MIN_CONFIDENCE_THRESHOLD = 0.6; // Confian√ßa m√≠nima para mudan√ßa
  const EMOTION_CHANGE_COOLDOWN = 5000; // 5 segundos entre mudan√ßas
  const STABILITY_BONUS = 0.15; // B√¥nus para emo√ß√µes consistentes

  const loadModels = async () => {
    try {
      console.log('ü§ñ Inicializando detec√ß√£o facial estabilizada...');
      setError(null);
      
      // Criar canvas para an√°lise de imagem
      if (!canvasRef.current) {
        canvasRef.current = document.createElement('canvas');
        canvasRef.current.width = 320;
        canvasRef.current.height = 240;
      }

      setIsModelLoaded(true);
      console.log('‚úÖ Detec√ß√£o facial pronta com sistema de estabilidade');
    } catch (err) {
      console.error('‚ùå Erro na inicializa√ß√£o:', err);
      setError('Erro na inicializa√ß√£o. Continuando com detec√ß√£o b√°sica.');
      setIsModelLoaded(true);
    }
  };

  const analyzeFrame = (videoElement: HTMLVideoElement): FaceDetectionResult => {
    if (!canvasRef.current) return { emotion: 'neutro', confidence: 0.3 };

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return { emotion: 'neutro', confidence: 0.3 };

    // Capturar frame do v√≠deo
    ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
    const currentFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
    // An√°lise de movimento e brilho
    let movement = 0;
    let brightness = 0;
    let edgeIntensity = 0;
    
    if (previousFrameRef.current) {
      const prev = previousFrameRef.current.data;
      const curr = currentFrame.data;
      
      for (let i = 0; i < curr.length; i += 4) {
        // Calcular diferen√ßa entre frames (movimento)
        const diff = Math.abs(curr[i] - prev[i]) + 
                    Math.abs(curr[i + 1] - prev[i + 1]) + 
                    Math.abs(curr[i + 2] - prev[i + 2]);
        movement += diff;
        
        // Calcular brilho m√©dio
        brightness += (curr[i] + curr[i + 1] + curr[i + 2]) / 3;
        
        // Calcular intensidade de bordas (aproxima√ß√£o)
        if (i > 0 && i < curr.length - 4) {
          const gradientX = Math.abs(curr[i] - curr[i - 4]);
          const gradientY = Math.abs(curr[i] - curr[i + canvas.width * 4]);
          edgeIntensity += Math.sqrt(gradientX * gradientX + gradientY * gradientY);
        }
      }
    }
    
    previousFrameRef.current = currentFrame;
    
    // Normalizar valores
    const pixelCount = canvas.width * canvas.height;
    movement = movement / (pixelCount * 3);
    brightness = brightness / pixelCount;
    edgeIntensity = edgeIntensity / pixelCount;
    
    // L√≥gica melhorada para detec√ß√£o de emo√ß√µes
    let detectedEmotion: DetectedEmotion;
    let baseConfidence: number;
    
    if (movement > 20 && edgeIntensity > 8) {
      // Muito movimento e mudan√ßas = surpreso ou feliz
      detectedEmotion = Math.random() > 0.5 ? 'surpreso' : 'feliz';
      baseConfidence = 0.7 + Math.random() * 0.2;
    } else if (movement < 3 && brightness < 80) {
      // Pouco movimento e baixo brilho = cansado ou triste
      detectedEmotion = Math.random() > 0.6 ? 'cansado' : 'triste';
      baseConfidence = 0.6 + Math.random() * 0.2;
    } else if (brightness > 120 && movement > 8) {
      // Brilho alto e movimento moderado = feliz
      detectedEmotion = 'feliz';
      baseConfidence = 0.75 + Math.random() * 0.15;
    } else if (movement > 15 && brightness < 100) {
      // Movimento alto e brilho baixo = raiva
      detectedEmotion = 'raiva';
      baseConfidence = 0.65 + Math.random() * 0.2;
    } else {
      // Casos neutros ou aleat√≥rios
      const emotions: DetectedEmotion[] = ['neutro', 'feliz', 'calmo'];
      detectedEmotion = emotions[Math.floor(Math.random() * emotions.length)] as DetectedEmotion;
      baseConfidence = 0.5 + Math.random() * 0.3;
    }
    
    return { emotion: detectedEmotion, confidence: baseConfidence };
  };

  const smoothEmotionDetection = (newResult: FaceDetectionResult): FaceDetectionResult | null => {
    const now = Date.now();
    
    // Adicionar ao hist√≥rico
    emotionHistoryRef.current.push({
      emotion: newResult.emotion,
      confidence: newResult.confidence,
      timestamp: now
    });
    
    // Manter apenas as √∫ltimas detec√ß√µes
    if (emotionHistoryRef.current.length > HISTORY_SIZE) {
      emotionHistoryRef.current.shift();
    }
    
    // Calcular consenso das √∫ltimas detec√ß√µes
    const recentHistory = emotionHistoryRef.current.slice(-3); // √öltimas 3
    const emotionCounts: Record<string, number> = {};
    let totalConfidence = 0;
    
    recentHistory.forEach(entry => {
      emotionCounts[entry.emotion] = (emotionCounts[entry.emotion] || 0) + 1;
      totalConfidence += entry.confidence;
    });
    
    // Encontrar emo√ß√£o mais frequente
    const mostFrequentEmotion = Object.keys(emotionCounts).reduce((a, b) => 
      emotionCounts[a] > emotionCounts[b] ? a : b
    ) as DetectedEmotion;
    
    // Calcular confian√ßa suavizada
    const avgConfidence = totalConfidence / recentHistory.length;
    
    // Aplicar b√¥nus de estabilidade se a emo√ß√£o √© consistente
    let finalConfidence = avgConfidence;
    const consistency = emotionCounts[mostFrequentEmotion] / recentHistory.length;
    if (consistency >= 0.6) {
      finalConfidence += STABILITY_BONUS * consistency;
      finalConfidence = Math.min(finalConfidence, 0.95); // Cap m√°ximo
    }
    
    // Verificar se deve aplicar mudan√ßa
    const timeSinceLastChange = now - lastEmotionChangeRef.current;
    const shouldChange = finalConfidence >= MIN_CONFIDENCE_THRESHOLD && 
                        (mostFrequentEmotion !== currentEmotion || 
                         timeSinceLastChange > EMOTION_CHANGE_COOLDOWN);
    
    if (shouldChange) {
      lastEmotionChangeRef.current = now;
      console.log(`üé≠ Emo√ß√£o estabilizada: ${mostFrequentEmotion} (confian√ßa: ${Math.round(finalConfidence * 100)}%)`);
      return { emotion: mostFrequentEmotion, confidence: finalConfidence };
    }
    
    return null; // N√£o mudou
  };

  const detectFaceExpression = async (videoElement: HTMLVideoElement): Promise<FaceDetectionResult | null> => {
    try {
      if (!isModelLoaded) return null;

      const rawResult = analyzeFrame(videoElement);
      const smoothedResult = smoothEmotionDetection(rawResult);
      
      return smoothedResult || { emotion: currentEmotion || 'neutro', confidence };
    } catch (err) {
      console.error('‚ùå Erro na detec√ß√£o:', err);
      return null;
    }
  };

  const startDetection = (videoElement: HTMLVideoElement) => {
    if (!isModelLoaded || isDetecting) return;

    setIsDetecting(true);
    console.log('üîÑ Iniciando detec√ß√£o estabilizada...');
    
    // Limpar hist√≥rico anterior
    emotionHistoryRef.current = [];
    lastEmotionChangeRef.current = 0;

    detectionIntervalRef.current = setInterval(async () => {
      const result = await detectFaceExpression(videoElement);
      
      if (result) {
        setCurrentEmotion(result.emotion);
        setConfidence(result.confidence);
        
        if (onEmotionChange && result.confidence > MIN_CONFIDENCE_THRESHOLD) {
          onEmotionChange(result.emotion);
        }
      }
    }, 2000); // Detectar a cada 2 segundos para melhor estabilidade
  };

  const stopDetection = () => {
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
    setIsDetecting(false);
    setCurrentEmotion(null);
    previousFrameRef.current = null;
    emotionHistoryRef.current = [];
    console.log('‚èπÔ∏è Detec√ß√£o estabilizada parada');
  };

  useEffect(() => {
    return () => {
      stopDetection();
    };
  }, []);

  return {
    isModelLoaded,
    currentEmotion,
    confidence,
    isDetecting,
    error,
    loadModels,
    startDetection,
    stopDetection
  };
};
